# ============================================================
# DISSERTAÇÃO | CÓDIGO ÚNICO E AUTOMÁTICO (ROBUSTO + "ARTIGO")
# ATUALIZAÇÕES (SEU PEDIDO):
# - selected_yields_monthly: degradê em VERDE
# - yields_surface_daily (3D): colormap azul→verde→amarelo (viridis)
# - r1mo_monthly: agora em TAXA ANUAL (aprox. *12) e em "x1200" como os demais
# - tabelas: até 3 casas, vírgula como separador decimal
# - notas: não centralizadas; uso \justifying (requer \usepackage{ragged2e})
# - “M2, M3…” vira coluna "Maturidade" com os números
# - MSPE: UMA tabela só, comparando HE, PC5 e Adrian contra RW, com asteriscos via DM (unilateral)
# - removi blocos duplicados antigos que referenciavam MSPE_ratio/dm_pv_rw (fonte típica de erro)
# ============================================================

# ============================================
# 0) DRIVE + IMPORTS + CARREGAR PARQUET
# ============================================
from google.colab import drive
drive.mount('/content/drive')

import os
import numpy as np
import pandas as pd

import matplotlib.pyplot as plt
import matplotlib as mpl
from mpl_toolkits.mplot3d import Axes3D  # noqa: F401

import statsmodels.api as sm
from statsmodels.tsa.api import VAR
from scipy import stats
from sklearn.decomposition import PCA

# -------- Caminhos de saída (Overleaf-friendly) --------
OUT_DIR = "/content/outputs"
FIG_DIR = os.path.join(OUT_DIR, "figuras")
TAB_DIR = os.path.join(OUT_DIR, "tabelas")
os.makedirs(FIG_DIR, exist_ok=True)
os.makedirs(TAB_DIR, exist_ok=True)

# -------- Parquet --------
cache_path = "/content/drive/MyDrive/Colab artigo EctrII2025/yields_daily_100_yr_2006-01-01_2025-12-12_M1-M121.parquet"
assert os.path.exists(cache_path), "Arquivo parquet não encontrado no Drive."

print("Carregando parquet...")
yields_daily = pd.read_parquet(cache_path)

# Se a data não vier como index, tenta detectar coluna de data:
if not isinstance(yields_daily.index, pd.DatetimeIndex):
    date_cols = [c for c in yields_daily.columns if "date" in str(c).lower()]
    if date_cols:
        yields_daily[date_cols[0]] = pd.to_datetime(yields_daily[date_cols[0]])
        yields_daily = yields_daily.set_index(date_cols[0])
    else:
        raise ValueError("Não encontrei data no index nem coluna contendo 'date'.")

# ============================================
# 1) LIMPEZA E ORDENAÇÃO DAS COLUNAS (M1..)
# ============================================
def _mnum(c):
    try:
        return int(str(c).replace("M", ""))
    except:
        return 10**9

yields_daily = yields_daily.copy()
yields_daily.index = pd.to_datetime(yields_daily.index).normalize()
yields_daily = yields_daily.sort_index()
yields_daily = yields_daily.dropna(how="all")
yields_daily = yields_daily.loc[:, sorted(yields_daily.columns, key=_mnum)]

H_full = yields_daily.shape[1]
print("Daily shape:", yields_daily.shape, "| H_full:", H_full)
print("Daily dates:", yields_daily.index.min(), "->", yields_daily.index.max())

# ============================================
# 2) AMOSTRA MENSAL: ÚLTIMO DIA DISPONÍVEL NO MÊS
# ============================================
monthly_last = yields_daily.groupby([yields_daily.index.year, yields_daily.index.month]).tail(1)
monthly_last.index.name = "DATE"
yields_monthly = monthly_last.astype(float).sort_index()  # % a.a.

print("Monthly shape:", yields_monthly.shape)
print("Monthly dates:", yields_monthly.index.min(), "->", yields_monthly.index.max())

# ============================================
# 3) CONVERTER PARA TAXA MENSAL DECIMAL (/(100*12))
# ============================================
yields_m = yields_monthly / (100.0 * 12.0)  # mensal decimal
assert yields_m.shape[0] >= 24 and yields_m.shape[1] >= 10, "Amostra mensal ou maturidades insuficientes."

# ============================================
# 4) HELPERS GERAIS
# ============================================
def add_const(X):
    return sm.add_constant(X, has_constant="add")

def dm_test(e1, e2, h=1, alternative="less"):
    """
    Diebold-Mariano com loss quadrático; HAC com nlags=h-1.
    Retorna p-value por aproximação Normal.
    alternative="less": H1: modelo 1 tem MSPE menor que modelo 2.
    """
    e1 = np.asarray(e1).astype(float)
    e2 = np.asarray(e2).astype(float)
    m = np.isfinite(e1) & np.isfinite(e2)
    e1, e2 = e1[m], e2[m]
    d = e1**2 - e2**2
    Tn = d.shape[0]
    if Tn < 10:
        return np.nan
    lag = max(h - 1, 0)
    res = sm.OLS(d, np.ones((Tn, 1))).fit()
    cov = sm.stats.sandwich_covariance.cov_hac(res, nlags=lag)
    var_mean = cov[0, 0] / Tn
    if var_mean <= 0:
        return np.nan
    dm_stat = d.mean() / np.sqrt(var_mean)
    if alternative == "less":
        return float(stats.norm.cdf(dm_stat))
    if alternative == "greater":
        return float(1 - stats.norm.cdf(dm_stat))
    return float(2 * (1 - stats.norm.cdf(abs(dm_stat))))

def build_core_from_monthly(yields_m: pd.DataFrame):
    """
    Reconstrói yields_fin/yields_ini/rf/r_1mo/r_xs automaticamente.
    yields_m: T x H (mensal decimal; colunas M1..MH)
    """
    T, H = yields_m.shape
    maturities = np.array([_mnum(c) for c in yields_m.columns], dtype=int)

    yields_fin = yields_m.iloc[1:T, 0:H-1].copy()  # t=2..T, M1..M(H-1)
    yields_ini = yields_m.iloc[0:T-1, 1:H].copy()  # t=1..T-1, M2..MH

    mat_fin = maturities[0:H-1]
    mat_ini = maturities[1:H]

    mat_fin_rep = pd.DataFrame(np.tile(mat_fin, (T-1, 1)), index=yields_fin.index, columns=yields_fin.columns)
    mat_ini_rep = pd.DataFrame(np.tile(mat_ini, (T-1, 1)), index=yields_ini.index, columns=yields_ini.columns)

    rf_t = yields_m.iloc[0:T-1, 0].copy()
    rf_t.index = yields_ini.index
    rf = rf_t.rename("risk_free")

    rf_for_returns = rf_t.copy()
    rf_for_returns.index = yields_fin.index

    rf_rep_for_returns = pd.DataFrame(
        np.tile(rf_for_returns.values.reshape(-1, 1), (1, H-1)),
        index=yields_fin.index,
        columns=yields_fin.columns
    )

    # log P(t,n) ~ -n*y(t,n)
    mns_lnP_fin = yields_fin * mat_fin_rep
    mns_lnP_ini = yields_ini * mat_ini_rep

    # log-return de manter por 1 mês (aprox.)
    r_1mo = pd.DataFrame(
        (mns_lnP_ini.values - mns_lnP_fin.values),
        index=yields_fin.index,
        columns=yields_fin.columns
    )
    r_xs = r_1mo - rf_rep_for_returns

    return {
        "T": T, "H": H,
        "yields_fin": yields_fin,
        "yields_ini": yields_ini,
        "rf": rf,
        "rf_for_returns": rf_for_returns,
        "rf_rep_for_returns": rf_rep_for_returns,
        "r_1mo": r_1mo,
        "r_xs": r_xs
    }

# ============================================
# 4b) HELPERS: SALVAR FIGURAS E TABELAS
# ============================================
mpl.rcParams.update({
    "font.size": 12,
    "axes.titlesize": 13,
    "axes.labelsize": 12,
    "legend.fontsize": 10,
    "xtick.labelsize": 11,
    "ytick.labelsize": 11,
    "axes.spines.top": False,
    "axes.spines.right": False,
})

DECIMALS_TABLES = 3  # até 3 casas

def save_fig_pdf(fig, filename, tight=True):
    path = os.path.join(FIG_DIR, filename)
    if tight:
        fig.tight_layout()
    fig.savefig(path, format="pdf", bbox_inches="tight")
    plt.close(fig)
    print(f"Figura salva em: {path}")

def _to_booktabs(latex_str: str) -> str:
    s = latex_str
    s = s.replace("\\hline", "\\toprule", 1)
    s = s.replace("\\hline", "\\midrule", 1)
    last = s.rfind("\\hline")
    if last != -1:
        s = s[:last] + "\\bottomrule" + s[last + len("\\hline"):]
    return s

def _fmt_num_comma(x, d=3):
    if x is None:
        return ""
    try:
        xf = float(x)
        if not np.isfinite(xf):
            return ""
        s = f"{xf:.{d}f}"
        return s.replace(".", ",")
    except:
        return ""

def save_latex_table(
    df,
    name,
    caption=None,
    label=None,
    decimals=DECIMALS_TABLES,
    column_format=None,
    table_pos="!htbp",
    use_resizebox=True,
    footnote=None,
    include_index=False,
    convert_numeric_to_comma=True,
):
    """
    Salva DataFrame em LaTeX (.tex) pronto para Overleaf (ambiente table completo).
    Requer no Overleaf:
      \\usepackage{booktabs}
      \\usepackage{graphicx} (se use_resizebox=True)
      \\usepackage{ragged2e} (para \\justifying nas notas, se você usar)
    """
    df_out = df.copy()

    # 1) arredonda numéricos
    num_cols = df_out.select_dtypes(include=[np.number]).columns
    if len(num_cols) > 0:
        df_out[num_cols] = df_out[num_cols].round(decimals)

    # 2) opcional: converter numéricos em strings com vírgula
    if convert_numeric_to_comma and len(num_cols) > 0:
        for c in num_cols:
            df_out[c] = df_out[c].apply(lambda v: _fmt_num_comma(v, decimals))

    if column_format is None:
        # se include_index=False, não precisa do "l" extra do índice
        if include_index:
            column_format = "l" + "c" * df_out.shape[1]
        else:
            column_format = "c" * df_out.shape[1]

    tabular = df_out.to_latex(
        escape=False,
        index=include_index,
        caption=None,
        label=None,
        longtable=False,
        column_format=column_format
    )
    tabular = _to_booktabs(tabular)

    lines = []
    lines.append(f"\\begin{{table}}[{table_pos}]")
    lines.append("\\centering")
    if caption:
        lines.append(f"\\caption{{{caption}}}")
    if label:
        lines.append(f"\\label{{{label}}}")

    if use_resizebox:
        lines.append("\\resizebox{\\textwidth}{!}{%")
        lines.append(tabular.rstrip())
        lines.append("}%")
    else:
        lines.append(tabular.rstrip())

    if footnote:
        # Nota “não centralizada”: usa minipage + \justifying
        lines.append("\\\\[2pt]")
        lines.append("\\begin{minipage}{\\textwidth}")
        lines.append("\\footnotesize\\justifying")
        lines.append(footnote)
        lines.append("\\end{minipage}")

    lines.append("\\end{table}")
    out = "\n".join(lines) + "\n"

    path = os.path.join(TAB_DIR, f"{name}.tex")
    with open(path, "w", encoding="utf-8") as f:
        f.write(out)

    print(f"Tabela salva em: {path}")
    return path

# ============================================
# 5) CORE (mensal)
# ============================================
core = build_core_from_monthly(yields_m)
T, H = core["T"], core["H"]
r_1mo, r_xs = core["r_1mo"], core["r_xs"]
rf_for_returns = core["rf_for_returns"]

print("\nCore shapes:")
print("T:", T, "| H:", H)
print("r_1mo:", r_1mo.shape, "| r_xs:", r_xs.shape, "| rf_for_returns:", rf_for_returns.shape)

# ============================================
# 6) SELEÇÕES DE MATURIDADE
# ============================================
mats_tables = [2, 3, 9, 12, 24, 48, 72, 96]
mats_plots  = [2, 12, 24, 48, 96]

mats_cols_tables = [f"M{m}" for m in mats_tables if f"M{m}" in r_xs.columns]
mats_cols_plots  = [f"M{m}" for m in mats_plots  if f"M{m}" in r_xs.columns]

if len(mats_cols_tables) == 0:
    raise ValueError("Nenhuma maturidade de mats_tables existe em r_xs.columns.")

# ============================================
# 7) PCA (5 PCs) NOS YIELDS MENSAIS (para gráficos)
# ============================================
Y_mo = yields_monthly.astype(float).copy().dropna(how="any")
pca_global = PCA(n_components=5)
Y_center = Y_mo - Y_mo.mean(axis=0)
pc_scores_monthly_global = pd.DataFrame(
    pca_global.fit_transform(Y_center.values),
    index=Y_center.index,
    columns=[f"PC{i}" for i in range(1, 6)]
)

# ============================================
# 8) GRÁFICOS (limpos) -> PDFs
# ============================================

# 8.1 Selected yields (monthly) *1200 — degradê VERDE
fig, ax = plt.subplots(figsize=(8, 5))
y_mo1200 = (yields_m * 1200.0)

greens = plt.cm.Greens(np.linspace(0.45, 0.95, max(len(mats_cols_plots), 2)))
for k, cm in enumerate(mats_cols_plots):
    ax.plot(y_mo1200.index, y_mo1200[cm].values, label=cm, color=greens[k])

ax.set_ylim(0, 18)
ax.set_xlabel("Ano")
ax.set_ylabel("YTM (x1200)")
ax.legend(loc="lower left", frameon=False)
save_fig_pdf(fig, "selected_yields_monthly.pdf")

# 8.2 r1mo_monthly — agora em taxa ANUAL (aprox. *12), e em "x1200" como os outros
# (r_1mo é log-return mensal; anualização padrão em artigos: 12 * r_1mo)
fig, ax = plt.subplots(figsize=(8, 5))
r1mo_ann_x1200 = (r_1mo * 12.0 * 1200.0)  # anualizado e escalado
for cm in mats_cols_plots:
    if cm in r1mo_ann_x1200.columns:
        ax.plot(r1mo_ann_x1200.index, r1mo_ann_x1200[cm].values, label=cm, color=greens[mats_cols_plots.index(cm)])

ax.set_xlabel("Ano")
ax.set_ylabel("Retorno 1 mês (anualizado, x1200)")
ax.legend(loc="upper right", frameon=False)
save_fig_pdf(fig, "r1mo_monthly.pdf")

# 8.3 r_xs (% pontos) *100
fig, ax = plt.subplots(figsize=(8, 5))
for cm in mats_cols_plots:
    ax.plot(r_xs.index, (r_xs[cm] * 100).values, label=cm, color=greens[mats_cols_plots.index(cm)])
ax.set_ylim(-30, 30)
ax.set_xlabel("Ano")
ax.set_ylabel("Retorno em excesso (p.p.)")
ax.legend(loc="upper right", frameon=False)
save_fig_pdf(fig, "rxs_monthly.pdf")

# 8.4 PC scores mensais (global) *100 — legenda fora (evita sobreposição)
fig, ax = plt.subplots(figsize=(8, 5))
for c in pc_scores_monthly_global.columns:
    ax.plot(pc_scores_monthly_global.index, (pc_scores_monthly_global[c] * 100).values, label=c)
ax.set_ylim(-6, 6)
ax.set_xlabel("Ano")
ax.set_ylabel("Componentes Principais")
ax.legend(loc="center left", bbox_to_anchor=(1.02, 0.5), frameon=False)
save_fig_pdf(fig, "pc_scores_monthly.pdf")

# 8.5 yields_surface_daily (3D) — colormap azul→verde→amarelo (viridis)
Z = yields_daily.astype(float).values  # (Tdaily x H)
x_dates = yields_daily.index
y_mats = np.array([_mnum(c) for c in yields_daily.columns], dtype=float)

# downsample para não explodir PDF
max_t = 250
if Z.shape[0] > max_t:
    idx_ds = np.linspace(0, Z.shape[0] - 1, max_t).astype(int)
    Zp = Z[idx_ds, :]
else:
    Zp = Z

Xgrid = np.arange(Zp.shape[0])
Ygrid = y_mats
Xg, Yg = np.meshgrid(Xgrid, Ygrid, indexing="xy")
Zg = Zp.T  # (H x Tsub)

fig = plt.figure(figsize=(9, 6))
ax = fig.add_subplot(111, projection="3d")
surf = ax.plot_surface(Xg, Yg, Zg, cmap="viridis", linewidth=0, antialiased=True)
ax.set_xlabel("Tempo (índice)")
ax.set_ylabel("Maturidade (meses)")
ax.set_zlabel("Taxa (% a.a.)")
save_fig_pdf(fig, "yields_surface_daily.pdf", tight=False)

# ============================================
# 9) AVALIAÇÃO FORA-DA-AMOSTRA (SPLIT 50/50)
# ============================================
SPLIT_FRAC = 0.5
DEC = DECIMALS_TABLES

Y_full = yields_monthly.astype(float).copy()
Y_full = Y_full.loc[yields_m.index]  # garante alinhamento

T_full = len(Y_full.index)
split_idx = int(np.floor(SPLIT_FRAC * T_full))
split_idx = max(split_idx, 24)
split_idx = min(split_idx, T_full - 12)

train_month_idx = Y_full.index[:split_idx]
test_month_idx  = Y_full.index[split_idx:]

test_start = test_month_idx[0]
train_fx_idx = r_xs.index[r_xs.index < test_start]
test_fx_idx  = r_xs.index[r_xs.index >= test_start]
N_test = len(test_fx_idx)
if N_test < 24:
    raise ValueError("Teste OOS ficou curto demais. Ajuste SPLIT_FRAC ou verifique amostra.")

# -------- PCA OOS: estima na 1ª metade e aplica na 2ª --------
Y_train = Y_full.loc[train_month_idx].values
Y_mean = Y_train.mean(axis=0)

pca_oos = PCA(n_components=5)
pca_oos.fit(Y_train - Y_mean)

PC_full = pd.DataFrame(
    pca_oos.transform(Y_full.values - Y_mean),
    index=Y_full.index,
    columns=[f"PC{i}" for i in range(1, 6)]
)

# PCs alinhados ao índice de r_xs (T-1)
PC_ini = PC_full.loc[r_xs.index].copy()  # (T-1) x 5

# ============================================
# 10) ERROS DE PREVISÃO (OOS): RW, HE, PC5, ADRIAN
# ============================================

# -------- HE: previsão E[r_xs]=0 => erro = r_xs --------
err_he = r_xs.loc[test_fx_idx, mats_cols_tables].copy()

# -------- RW: previsão r_{t+1} = r_t --------
pos0 = r_xs.index.get_loc(test_fx_idx[0])
if pos0 < 1:
    raise ValueError("Não existe observação anterior para iniciar RW no teste.")

rw_fore = r_xs.iloc[pos0-1 : pos0-1 + N_test, :][mats_cols_tables].values
rw_real = r_xs.loc[test_fx_idx, mats_cols_tables].values
err_rw = pd.DataFrame(rw_real - rw_fore, index=test_fx_idx, columns=mats_cols_tables)

# -------- PC5 (MQO irrestrito): estima no treino, prevê no teste --------
X_train = add_const(PC_ini.loc[train_fx_idx].values.astype(float))
X_test  = add_const(PC_ini.loc[test_fx_idx].values.astype(float))

err_pc5 = pd.DataFrame(index=test_fx_idx, columns=mats_cols_tables, dtype=float)
for col in mats_cols_tables:
    ytr = r_xs.loc[train_fx_idx, col].values.astype(float)
    msk = np.isfinite(ytr) & np.all(np.isfinite(X_train), axis=1)
    res = sm.OLS(ytr[msk], X_train[msk, :]).fit()
    yhat = X_test @ res.params
    ytrue = r_xs.loc[test_fx_idx, col].values.astype(float)
    err_pc5[col] = ytrue - yhat

# -------- Adrian 3 steps (OOS): Step 2 com choques VAR + PCs --------
# Step 1: VAR(1) nos PCs (treino)
pc_train = PC_full.loc[train_month_idx].values.astype(float)
var_model = VAR(pc_train)
var1 = var_model.fit(1, trend="c")

c_vec = var1.params[0, :]       # (5,)
A_mat = var1.coefs[0, :, :]     # (5x5)

# choques v_t no período todo (a partir do 2º mês)
Vhat = np.full_like(PC_full.values, np.nan)
pc_all = PC_full.values.astype(float)
for t in range(1, len(PC_full.index)):
    Vhat[t, :] = pc_all[t, :] - (c_vec + A_mat @ pc_all[t-1, :])

Vhat_df = pd.DataFrame(Vhat, index=PC_full.index, columns=[f"V{i}" for i in range(1, 6)])
Vhat_fx = Vhat_df.loc[r_xs.index].copy()  # alinha com retornos (T-1 x 5)

# Sigma_hat (treino)
Vhat_train_fx = Vhat_fx.loc[train_fx_idx].values.astype(float)
Vhat_train_fx = Vhat_train_fx[np.all(np.isfinite(Vhat_train_fx), axis=1)]
Sigma_hat = (Vhat_train_fx.T @ Vhat_train_fx) / max((Vhat_train_fx.shape[0] - 6), 1)

# Step 1b: U_hat via yields_m ~ PCs (treino), residual aplicado no período todo
Uy = np.zeros_like(yields_m.values.astype(float))
Xy_train = add_const(PC_full.loc[train_month_idx].values.astype(float))
Xy_all   = add_const(PC_full.values.astype(float))

for j in range(yields_m.shape[1]):
    yj_train = yields_m.loc[train_month_idx].iloc[:, j].values.astype(float)
    msk = np.isfinite(yj_train) & np.all(np.isfinite(Xy_train), axis=1)
    res = sm.OLS(yj_train[msk], Xy_train[msk, :]).fit()
    Uy[:, j] = yields_m.iloc[:, j].values.astype(float) - (Xy_all @ res.params)

U_ini = Uy[0:T-1, 1:H]  # (T-1)x(H-1), colunas M2..MH
U_ini_df = pd.DataFrame(U_ini, index=r_xs.index, columns=r_xs.columns)

# Step 2: r_xs ~ [Vhat, PCs] (treino)
Z_train = np.hstack([Vhat_fx.loc[train_fx_idx].values.astype(float),
                     PC_ini.loc[train_fx_idx].values.astype(float)])
Z_test  = np.hstack([Vhat_fx.loc[test_fx_idx].values.astype(float),
                     PC_ini.loc[test_fx_idx].values.astype(float)])
Zc_train = add_const(Z_train)
Zc_test  = add_const(Z_test)

H_minus1 = r_xs.shape[1]
a_hat_A = np.zeros(H_minus1)
beta_hat_A = np.zeros((5, H_minus1))
c_hat_A = np.zeros((5, H_minus1))
Ehat_train = np.full((len(train_fx_idx), H_minus1), np.nan)

for j, col in enumerate(r_xs.columns):
    ytr = r_xs.loc[train_fx_idx, col].values.astype(float)
    msk = np.isfinite(ytr) & np.all(np.isfinite(Zc_train), axis=1)
    res = sm.OLS(ytr[msk], Zc_train[msk, :]).fit()

    a_hat_A[j] = res.params[0]
    beta_hat_A[:, j] = res.params[1:6]     # V1..V5
    c_hat_A[:, j]    = res.params[6:11]    # PC1..PC5

    tmp = np.full(len(train_fx_idx), np.nan)
    tmp[msk] = res.resid
    Ehat_train[:, j] = tmp

sig2_hat = np.nanmean(Ehat_train**2)

def vec_outer(b):
    return np.outer(b, b).reshape(-1, order="F")

B_ast = np.column_stack([vec_outer(beta_hat_A[:, i]) for i in range(H_minus1)])  # 25 x (H-1)
vec_Sigma = Sigma_hat.reshape(-1, order="F").reshape(-1, 1)
B_ast_vecSigma = (B_ast.T @ vec_Sigma).reshape(-1)

idx0_sel_adrian = [m - 1 for m in mats_tables if (m - 1) < H_minus1]
if len(idx0_sel_adrian) >= 3:
    B = beta_hat_A[:, idx0_sel_adrian].T
    C = c_hat_A[:, idx0_sel_adrian].T
    Lambda_hat = np.linalg.solve(B.T @ B, B.T @ C)
else:
    Lambda_hat = np.zeros((5, 5))

term = a_hat_A + (B_ast_vecSigma + sig2_hat) / 2.0
term_vec = term.reshape(-1, 1)

betabeta_inv = np.linalg.pinv(beta_hat_A @ beta_hat_A.T)
lambda_hat = betabeta_inv @ (beta_hat_A @ term_vec)  # 5x1

t_beta_lambda = (beta_hat_A.T @ lambda_hat).reshape(1, -1)  # 1 x (H-1)
kappa_hat = t_beta_lambda - ((B_ast_vecSigma + sig2_hat) / 2.0).reshape(1, -1)
Kappa_hat_T = (Lambda_hat.T @ beta_hat_A)  # 5 x (H-1)

# previsão Adrian no teste:
Xtest_pc = PC_ini.loc[test_fx_idx].values.astype(float)   # (N_test x 5)
E_adrian_test = (np.ones((N_test, 1)) @ kappa_hat) + (Xtest_pc @ Kappa_hat_T) + U_ini_df.loc[test_fx_idx].values
ytrue_test_all = r_xs.loc[test_fx_idx].values.astype(float)

err_adrian_all = ytrue_test_all - E_adrian_test
err_adrian_all_df = pd.DataFrame(err_adrian_all, index=test_fx_idx, columns=r_xs.columns)
err_adrian = err_adrian_all_df[mats_cols_tables].copy()

# ============================================
# 11) TABELA ÚNICA — MSPE ratio vs RW (HE, PC5, Adrian) + asteriscos DM
# ============================================

def _mspe(err_df):
    return (err_df.astype(float)**2).mean(axis=0)

def _stars(p):
    if p is None or (isinstance(p, float) and (np.isnan(p) or np.isinf(p))):
        return ""
    if p <= 0.01:
        return "***"
    if p <= 0.05:
        return "**"
    if p <= 0.10:
        return "*"
    return ""

# MSPE por maturidade
mspe_rw = _mspe(err_rw)
mspe_he = _mspe(err_he)
mspe_pc5 = _mspe(err_pc5)
mspe_adrian = _mspe(err_adrian)

# Ratios vs RW
ratio_he_rw = (mspe_he / mspe_rw)
ratio_pc5_rw = (mspe_pc5 / mspe_rw)
ratio_adrian_rw = (mspe_adrian / mspe_rw)

# DM p-values (unilateral: modelo na coluna melhor que RW)
dm_he_rw = {}
dm_pc5_rw = {}
dm_adrian_rw = {}
for col in mats_cols_tables:
    dm_he_rw[col] = dm_test(err_he[col].values, err_rw[col].values, h=1, alternative="less")
    dm_pc5_rw[col] = dm_test(err_pc5[col].values, err_rw[col].values, h=1, alternative="less")
    dm_adrian_rw[col] = dm_test(err_adrian[col].values, err_rw[col].values, h=1, alternative="less")

# montar tabela com "Maturidade" numérica
rows = []
for cm in mats_cols_tables:
    mnum = _mnum(cm)
    rows.append({
        "Maturidade": int(mnum),
        "Hipótese das Expectativas": f"{_fmt_num_comma(ratio_he_rw[cm], DEC)}{_stars(dm_he_rw[cm])}",
        "Reg. Retorno Comp. Principais": f"{_fmt_num_comma(ratio_pc5_rw[cm], DEC)}{_stars(dm_pc5_rw[cm])}",
        "Restrito à Arbitragem": f"{_fmt_num_comma(ratio_adrian_rw[cm], DEC)}{_stars(dm_adrian_rw[cm])}",
    })

Table_MSPE_all_vs_RW = pd.DataFrame(rows).sort_values("Maturidade").reset_index(drop=True)
display(Table_MSPE_all_vs_RW)

# nota padrão artigo (com mecanismo do split)
periodo_ini = yields_monthly.index.min().strftime("%B-%Y").lower()
periodo_fim = yields_monthly.index.max().strftime("%B-%Y").lower()
teste_ini = test_fx_idx.min().strftime("%B-%Y").lower()
teste_fim = test_fx_idx.max().strftime("%B-%Y").lower()

nota_mspe = (
    "Fonte: Elaborado pelo Autor. \\\\ "
    "Notas: Razões de MSPE fora da amostra, normalizadas em relação ao passeio aleatório (RW). "
    "A amostra é dividida em duas metades: estimam-se os pesos dos fatores (PCA) na primeira metade "
    "e aplicam-se esses pesos aos \\textit{yields} da segunda metade, a qual é usada para avaliação. "
    "Um, dois e três asteriscos indicam reduções de MSPE estatisticamente significativas nos níveis de "
    "10\\% (*), 5\\% (**), e 1\\% (***), com base no teste unilateral de Diebold e Mariano (1995), "
    "com hipótese alternativa de que o modelo na coluna possui MSPE menor que RW. "
    f"O período amostral é de {periodo_ini} a {periodo_fim}. "
    f"O período de teste é de {teste_ini} a {teste_fim}. "
    f"O tamanho amostral efetivo no teste é N={N_test}."
)

save_latex_table(
    Table_MSPE_all_vs_RW,
    "MSPE_ratio_all_vs_RW_oos",
    caption="Razão MSPE fora da amostra: modelos versus passeio aleatório",
    label="tab:MSPE_all_vs_RW_oos",
    decimals=DEC,
    use_resizebox=True,
    footnote=nota_mspe,
    include_index=False,              # sem índice; já temos coluna Maturidade
    convert_numeric_to_comma=False,   # já formatamos como string com vírgula nas colunas de ratio
    column_format="lccc"
)

# ============================================
# 12) GRÁFICOS (mensais) no PERÍODO DE TESTE:
# 1) yield prevista vs realizada
# 2) r_xs prevista vs realizada
# ============================================

# escolha do vencimento
MAT_YIELD_PLOT = "M24"
MAT_RXS_PLOT   = "M24"
MODEL_RXS = "pc5"  # "pc5", "adrian" ou "he"

if MAT_YIELD_PLOT not in yields_monthly.columns:
    raise ValueError(f"{MAT_YIELD_PLOT} não está em yields_monthly.columns")
if MAT_RXS_PLOT not in r_xs.columns:
    raise ValueError(f"{MAT_RXS_PLOT} não está em r_xs.columns")

# índices de teste
test_month_idx = yields_monthly.index[yields_monthly.index >= test_start]
train_month_idx = yields_monthly.index[yields_monthly.index < test_start]

# 12.1 Yield prevista vs realizada (modelo: yield = a + b'PC)
PC_month = PC_full.loc[yields_monthly.index].copy()
Xy_train = add_const(PC_month.loc[train_month_idx].values.astype(float))
Xy_test  = add_const(PC_month.loc[test_month_idx].values.astype(float))

y_train = yields_monthly.loc[train_month_idx, MAT_YIELD_PLOT].values.astype(float)
msk = np.isfinite(y_train) & np.all(np.isfinite(Xy_train), axis=1)
res_y = sm.OLS(y_train[msk], Xy_train[msk, :]).fit()

yhat_test = Xy_test @ res_y.params
ytrue_test = yields_monthly.loc[test_month_idx, MAT_YIELD_PLOT].values.astype(float)

fig, ax = plt.subplots(figsize=(8.5, 4.8))
ax.plot(test_month_idx, ytrue_test, label="Realizada")
ax.plot(test_month_idx, yhat_test, label="Prevista")
ax.set_xlabel("Ano")
ax.set_ylabel("Yield (% a.a.)")
ax.legend(loc="upper left", frameon=False)
save_fig_pdf(fig, f"yield_prevista_vs_realizada_{MAT_YIELD_PLOT}.pdf")

# 12.2 r_xs previsto vs realizado
PC_fx = PC_ini.copy()
Xr_train = add_const(PC_fx.loc[train_fx_idx].values.astype(float))
Xr_test  = add_const(PC_fx.loc[test_fx_idx].values.astype(float))

ytr = r_xs.loc[train_fx_idx, MAT_RXS_PLOT].values.astype(float)
msk = np.isfinite(ytr) & np.all(np.isfinite(Xr_train), axis=1)

if MODEL_RXS == "he":
    rhat_test = np.zeros(len(test_fx_idx), dtype=float)
elif MODEL_RXS == "pc5":
    res_r = sm.OLS(ytr[msk], Xr_train[msk, :]).fit()
    rhat_test = Xr_test @ res_r.params
elif MODEL_RXS == "adrian":
    # previsão = realizada - erro (já temos err_adrian_all_df no OOS)
    rhat_test = (r_xs.loc[test_fx_idx, MAT_RXS_PLOT] - err_adrian_all_df.loc[test_fx_idx, MAT_RXS_PLOT]).values
else:
    raise ValueError("MODEL_RXS deve ser 'pc5', 'adrian' ou 'he'.")

rtrue_test = r_xs.loc[test_fx_idx, MAT_RXS_PLOT].values.astype(float)

fig, ax = plt.subplots(figsize=(8.5, 4.8))
ax.plot(test_fx_idx, rtrue_test * 100, label="Realizado")
ax.plot(test_fx_idx, rhat_test * 100, label="Previsto")
ax.set_xlabel("Ano")
ax.set_ylabel("Retorno em excesso (p.p.)")
ax.legend(loc="upper left", frameon=False)
save_fig_pdf(fig, f"rxs_previsto_vs_realizado_{MODEL_RXS}_{MAT_RXS_PLOT}.pdf")

print("OK: tabelas e gráficos gerados.")

# ============================================
# 13) RESUMO
# ============================================
print("\n==== SAÍDAS GERADAS ====")
print("Figuras (PDF):", FIG_DIR)
print("Tabelas (LaTeX .tex):", TAB_DIR)
print("\nDica Overleaf (pacotes):")
print(r"- \usepackage{booktabs}")
print(r"- \usepackage{graphicx}")
print(r"- \usepackage{ragged2e}  % para \justifying nas notas")
print("\nDica Overleaf (inclusão):")
print(r"- \includegraphics{figuras/selected_yields_monthly.pdf}")
print(r"- \input{tabelas/MSPE_ratio_all_vs_RW_oos.tex}")
